-- Master's Theis wbk Institute of Production Science, KIT: Process Monitoring in Additive Manufacturing Through Machine Learning

Industry 4.0 denotes the trend toward utilizing data-centric, automated systems in production technologies facilitated by 
cutting-edge technologies like the Internet of Things and artificial intelligence. With the availability of data and strong 
hardware, machine learning can handle complex problems in production.
Additionally, additive manufacturing is being directly used in the construction of products. 
However, process inconsistencies that occur due to this production technology’s nature pose obstacles. 
Consequently, it is difficult to utilize additive manufacturing to construct highly stressed, strength-critical parts.
To address this problem, a technology for process monitoring is being developed on the basis of powder bed fusion of metals 
using laser beam technology, whereby pores in additive-manufactured parts via acoustic signals during manufacturing processes 
are detected. This study aims to detect pores in the field of additive manufacturing by processing acoustic signals using machine-learning methods.

<img width="539" alt="image" src="https://github.com/user-attachments/assets/f8c31aac-3c7b-4956-968c-8fd3360906a6" />

The figure above illustrates the signal data acquisition process employed in this study. As depicted, a laser source directs beams onto an additively manufactured part. 
When the laser beams interact with the part, acoustic signals are generated within it. 
These signals are captured by a sensor positioned beneath the build plate. Since additive manufacturing constructs parts 
layer by layer, these acoustic signals serve as indicators to identify the presence of pores in the individual layers that make up the part.





-- Seminar Work at AIFB, KIT: Modern CNN Architectures and Training Methods 

Since the advent of convolutional neural networks (CNNs), numerous innovative ideas related to their architecture and training methods have emerged. These advancements have significantly contributed to enhancing the performance and versatility of CNNs in various applications. Architectural improvements, such as the introduction of novel layers, activation functions, and attention mechanisms, alongside innovative training techniques, including optimization strategies and data augmentation methods, have driven the evolution of CNNs. This paper delves into the most notable advancements in CNN architectures and training methodologies introduced over the past three years, highlighting their impact on the field and their potential for future research.

<img width="865" alt="Kognitive Automobile und Roboter" src="https://github.com/user-attachments/assets/fc309241-89b7-4c84-b981-a8372d7ee834" />






-- Master Seminar at IISM, KIT: Deep Reinforcement Learning Experiments in the Collector Environment

Deep Reinforcement Learning (DRL) has emerged as a critical area in the field of Artificial Intelligence, showcasing its potential in solving complex decision-making problems. Grid-world environments serve as valuable tools for researchers to conduct Reinforcement Learning experiments and evaluate the effectiveness of various algorithms in a controlled and interpretable setting. Among these, the collector environment—a grid-based simulation—provides a platform where an agent navigates through a grid world to complete assigned tasks. This environment not only facilitates experimentation but also enables benchmarking the performance of DRL algorithms.

Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) are two widely recognized DRL algorithms in the literature, known for their efficiency and robustness in various environments. This study focuses on utilizing the collector environment to conduct comprehensive DRL experiments with these algorithms. The experiments include implementing DQN and PPO, benchmarking their performance, and systematically modifying the training environment. By doing so, this research aims to observe and analyze how changes in the environment influence the agents' behavior and performance, providing valuable insights into the dynamics of DRL algorithms in grid-based settings.

![minigrid_-_Collector-5x5-v0](https://github.com/user-attachments/assets/a23efcbe-2f40-4019-a57d-91a984c936ec)


